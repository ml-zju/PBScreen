{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a1ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a trained SVM model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the SVM model\n",
    "    svm = SVC(probability=True, random_state=42)\n",
    "    svm.fit(x_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    train_accuracy = svm.score(x_train, y_train)\n",
    "    test_accuracy = svm.score(x_test, y_test)\n",
    "    valid_accuracy = svm.score(x_valid, y_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a trained SVM model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the SVM model\n",
    "    svm = SVC(probability=True, random_state=42)\n",
    "    svm.fit(x_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    train_accuracy = svm.score(x_train, y_train)\n",
    "    test_accuracy = svm.score(x_test, y_test)\n",
    "    valid_accuracy = svm.score(x_valid, y_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_random_forest_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a Random Forest model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the Random Forest model\n",
    "    rf = RandomForestClassifier(n_estimators=180, random_state=42)\n",
    "    rf.fit(x_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    train_accuracy = rf.score(x_train, y_train)\n",
    "    test_accuracy = rf.score(x_test, y_test)\n",
    "    valid_accuracy = rf.score(x_valid, y_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_random_forest_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"Random Forest Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"Random Forest Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"Random Forest Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b12d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_mlp_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of an MLP model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the MLP model\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(64,), max_iter=1000, alpha=0.01, random_state=42)\n",
    "    mlp.fit(x_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    train_accuracy = mlp.score(x_train, y_train)\n",
    "    test_accuracy = mlp.score(x_test, y_test)\n",
    "    valid_accuracy = mlp.score(x_valid, y_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_mlp_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"MLP Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"MLP Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"MLP Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_knn_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a KNN model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the KNN model\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    train_accuracy = knn.score(x_train, y_train)\n",
    "    test_accuracy = knn.score(x_test, y_test)\n",
    "    valid_accuracy = knn.score(x_valid, y_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_knn_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"KNN Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"KNN Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"KNN Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24265a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_catboost_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a CatBoost model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the CatBoost model\n",
    "    catboost_model = CatBoostClassifier(iterations=100, random_state=42)\n",
    "    catboost_model.fit(x_train, y_train)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    train_accuracy = catboost_model.score(x_train, y_train)\n",
    "    test_accuracy = catboost_model.score(x_test, y_test)\n",
    "    valid_accuracy = catboost_model.score(x_valid, y_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_catboost_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"CatBoost Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"CatBoost Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"CatBoost Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_lightgbm_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a LightGBM model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the LightGBM model\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "       'metric': 'binary_logloss',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9\n",
    "    }\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=100,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=5)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    y_pred_train = gbm.predict(x_train)\n",
    "    y_pred_train[y_pred_train >= 0.5] = 1\n",
    "    y_pred_train[y_pred_train < 0.5] = 0\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "    y_pred_test = gbm.predict(x_test)\n",
    "    y_pred_test[y_pred_test >= 0.5] = 1\n",
    "    y_pred_test[y_pred_test < 0.5] = 0\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    y_pred_valid = gbm.predict(x_valid)\n",
    "    y_pred_valid[y_pred_valid >= 0.5] = 1\n",
    "    y_pred_valid[y_pred_valid < 0.5] = 0\n",
    "    valid_accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_lightgbm_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"LightGBM Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"LightGBM Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"LightGBM Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def calculate_xgboost_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of an XGBoost model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Create and train the XGBoost model\n",
    "    dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "    dvalid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'error',\n",
    "        'gamma': 0.1,\n",
    "       'min_child_weight': 1.1,\n",
    "       'max_depth': 5,\n",
    "        'lambda': 10,\n",
    "       'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'colsample_bylevel': 0.7,\n",
    "        'eta': 0.01,\n",
    "        'tree_method': 'exact',\n",
    "       'seed': 42\n",
    "    }\n",
    "    num_round = 100\n",
    "    watchlist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "    model = xgb.train(params, dtrain, num_round, watchlist)\n",
    "\n",
    "    # Calculate accuracy on training, test, and validation subsets\n",
    "    y_pred_train = model.predict(dtrain)\n",
    "    y_pred_train[y_pred_train >= 0.5] = 1\n",
    "    y_pred_train[y_pred_train < 0.5] = 0\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "    y_pred_test = model.predict(dtest)\n",
    "    y_pred_test[y_pred_test >= 0.5] = 1\n",
    "    y_pred_test[y_pred_test < 0.5] = 0\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    y_pred_valid = model.predict(dvalid)\n",
    "    y_pred_valid[y_pred_valid >= 0.5] = 1\n",
    "    y_pred_valid[y_pred_valid < 0.5] = 0\n",
    "    valid_accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_xgboost_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"XGBoost Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"XGBoost Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"XGBoost Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef352bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_stacking_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a Stacking model on training, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        x_test (numpy.ndarray): Test data features.\n",
    "        y_test (numpy.ndarray): Test data labels.\n",
    "        x_valid (numpy.ndarray): Validation data features.\n",
    "        y_valid (numpy.ndarray): Validation data labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three floats representing the accuracy on the training, test, and validation sets respectively.\n",
    "    \"\"\"\n",
    "    # Bese Models Definition\n",
    "    CATBoostModel = CatBoostClassifier(learning_rate=0.04, depth=7, l2_leaf_reg=9)\n",
    "    KNeighborsModel = KNeighborsClassifier(n_neighbors=3)\n",
    "    LGBMModel = lgb.LGBMClassifier(learning_rate=0.5, max_depth=6)\n",
    "    NeuralNetworkModel = MLPClassifier(max_iter=2000, alpha=0.01, random_state=42, hidden_layer_sizes=(65))\n",
    "    RandomForestModel = RandomForestClassifier(n_estimators=190, max_depth=12, random_state=90)\n",
    "    SVMModel = SVC(gamma=0.08, C=3.5, probability=True, random_state=42)\n",
    "    XGBoostModel = xgb.XGBClassifier(max_depth=7, learning_rate=0.4)\n",
    "\n",
    "    # Stacking Model Construction\n",
    "    estimators = [\n",
    "        ('catboost', CATBoostModel),\n",
    "        ('knn', KNeighborsModel),\n",
    "        ('lgbm', LGBMModel),\n",
    "        ('neural_network', NeuralNetworkModel),\n",
    "        ('random_forest', RandomForestModel),\n",
    "        ('svm', SVMModel),\n",
    "        ('xgboost', XGBoostModel)\n",
    "    ]\n",
    "    stacking_model = StackingClassifier(estimators=estimators, final_estimator=RandomForestModel)\n",
    "\n",
    "    # Train Stacking Model\n",
    "    stacking_model.fit(x_train, y_train)\n",
    "\n",
    "    # Accuracy on Train Set\n",
    "    train_pred = stacking_model.predict(x_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "\n",
    "    # Accuracy on Test Set\n",
    "    test_pred = stacking_model.predict(x_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "\n",
    "    # Accuracy on Validation Set\n",
    "    valid_pred = stacking_model.predict(x_valid)\n",
    "    valid_accuracy = accuracy_score(y_valid, valid_pred)\n",
    "\n",
    "    return train_accuracy, test_accuracy, valid_accuracy\n",
    "\n",
    "def main():\n",
    "    # Assume data is a pandas DataFrame with columns 'finger' and 'TTE'\n",
    "    # Convert data to numpy arrays\n",
    "    x = np.array(list(data['finger']))\n",
    "    y = data['Label'].values\n",
    "\n",
    "    # Split the data into training, test, and validation sets\n",
    "    x_train, x_remainder, y_train, y_remainder = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    x_test, x_valid, y_test, y_valid = train_test_split(x_remainder, y_remainder, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_acc, test_acc, valid_acc = calculate_stacking_accuracy(x_train, y_train, x_test, y_test, x_valid, y_valid)\n",
    "\n",
    "    print(\"Stacking Training set accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"Stacking Test set accuracy: {:.3f}\".format(test_acc))\n",
    "    print(\"Stacking Validation set accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
